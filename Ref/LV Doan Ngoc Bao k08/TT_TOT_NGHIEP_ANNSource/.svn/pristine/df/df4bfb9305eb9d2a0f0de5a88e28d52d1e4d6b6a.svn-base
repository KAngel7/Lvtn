using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;


namespace NeuronNetwork
{
    public class Network
    {
        /**
         * Network parameter
         */
        /**
         * the number of input nodes of the network
         */
        public int m_iNumInputNodes;
        /*
         * the number of hiddden nodes of the network 
         */
        public int m_iNumHiddenNodes;
        /*
         * the number of output nodes of the network
         */
        public int m_iNumOutputNodes;

        public Perceptron[] m_arInputNodes; //array store all input nodes
        public Perceptron[] m_arHiddenNodes; //array store all hidden nodes
        public Perceptron[] m_arOutputNodes; //array store all output nodes

        public double[,] m_arInputHiddenConn; //2-dimensions array store all weight connected between input and hidden nodes
        public double[,] m_arHiddenOutputConn; //2-dimensions array store all weight connected between hidden and output nodes

        public double[] m_arHiddenBias; //array store all bias of hidden nodes
        public double[] m_arOutputBias; //array store all bias of output nodes

        /**
         * Constructor
         * Create a three-layer network with nInputNodes input nodes, nHiddenNodes hidden nodes
         * nOutputNodes outputnodes
         * Author: DataMining-Research08
         */
        public Network(int nInputNodes, int nHiddenNodes, int nOutputNodes)
        {
            //default parameter
            int i, j;
            m_iNumInputNodes = nInputNodes;
            m_iNumHiddenNodes = nHiddenNodes;
            m_iNumOutputNodes = nOutputNodes;
            m_arInputNodes = new Perceptron[m_iNumInputNodes];
            for (i = 0; i < m_iNumInputNodes; i++)
            {
                m_arInputNodes[i] = new Perceptron(ActionvationFunction.SIGMOID_FUNCTION);
            }
            m_arHiddenNodes = new Perceptron[m_iNumHiddenNodes];
            for (i = 0; i < m_iNumHiddenNodes; i++)
            {
                m_arHiddenNodes[i] = new Perceptron(ActionvationFunction.SIGMOID_FUNCTION);
            }
            m_arOutputNodes = new Perceptron[m_iNumOutputNodes];
            for (i = 0; i < m_iNumOutputNodes; i++)
            {
                m_arOutputNodes[i] = new Perceptron(ActionvationFunction.SIGMOID_FUNCTION);
            }
            m_arInputHiddenConn = new double[m_iNumHiddenNodes, m_iNumInputNodes];  //wij is weight from node j to node i
            m_arHiddenOutputConn = new double[m_iNumOutputNodes, m_iNumHiddenNodes];
            m_arHiddenBias = new double[m_iNumHiddenNodes];  // weight from bias node at input layer to hidden node
            m_arOutputBias = new double[m_iNumOutputNodes]; // weight from bias node at hidden layer to output node
            double rand = new Random().NextDouble();   // create a random double from 0.0 to 1.0
            for (i = 0; i < m_iNumHiddenNodes; i++)   // initialize bias values of Hidden nodes
                m_arHiddenBias[i] = rand;
            for (i = 0; i < m_iNumOutputNodes; i++)   // initialize bias values of Output nodes
                m_arOutputBias[i] = rand;
            for (i = 0; i < m_iNumHiddenNodes; i++)    // initialize weight of Input Hidden connection
            {
                for (j = 0; j < m_iNumInputNodes; j++)
                    m_arInputHiddenConn[i, j] = rand;
            }
            for (i = 0; i < m_iNumOutputNodes; i++)   // initialize weight of Hidden Output connection
            {
                for (j = 0; j < m_iNumHiddenNodes; j++)
                    m_arHiddenOutputConn[i, j] = rand;
            }

        }

        /**
         * Network import/export method
         */

        static public bool Import(string pathFile)
        {
            return false;
        }

        static public bool Export(string pathFile)
        {
            return false;
        }

        /*
         * training the network by Backpropogation algorithm
         * sample is data used to train 
         * Author: DataMining-Research08
         */
        public void Bp_Train(List<double> sample)
        {
            PB_Form form = new PB_Form();
            List<double> sample2 = new List<double>();
            if (form.ok == true)
            {
                /*convert input to [0.01-0.99]*/
                double max = sample.Max();
                double min = sample.Min();
                int count = sample.Count;
                for (int i = 0; i < count; i++)
                {
                    double a = sample.ElementAt(i);
                    double b = (a - min) / (max - min) * (0.99 - 0.01) + 0.01;
                    sample2.Add(b);
                }
                Bp_run(sample2, form.learn, form.momen, form.error);
                show();
                System.Windows.MessageBox.Show("Traning finish!!!");
            }

        }

        /*
         * Run the BackPropogatinon algorithm
         * Author: DataMining-Research08
         */
        public void Bp_run(List<double> sample, double learnRate, double momentum, double expectedError = 0.01)
        {
            int i, j;
            int epoch = 0;
            double MAE = Double.MaxValue;
            double[,] deltaInputHidden = new double[m_iNumHiddenNodes, m_iNumInputNodes];
            double[,] deltaHiddenOutput = new double[m_iNumOutputNodes, m_iNumHiddenNodes];
            double[,] LagdeltaInputHidden = new double[m_iNumHiddenNodes, m_iNumInputNodes];
            double[,] LagdeltaHiddenOutput = new double[m_iNumOutputNodes, m_iNumHiddenNodes];
            double[] deltaOutputBias = new double[m_iNumOutputNodes];
            double[] deltaHiddenBias = new double[m_iNumHiddenNodes];
            double[] LagdeltaOutputBias = new double[m_iNumOutputNodes];
            double[] LagdeltaHiddenBias = new double[m_iNumHiddenNodes];
            for (i = 0; i < m_iNumHiddenNodes; i++)    // initialize weight of Input Hidden connection
            {
                for (j = 0; j < m_iNumInputNodes; j++)
                {
                    deltaInputHidden[i, j] = 0.0;
                    LagdeltaInputHidden[i, j] = 0.0;
                }
                deltaHiddenBias[i] = 0.0;
                LagdeltaHiddenBias[i] = 0.0;
            }
            for (i = 0; i < m_iNumOutputNodes; i++)   // initialize weight of Hidden Output connection
            {
                for (j = 0; j < m_iNumHiddenNodes; j++)
                {
                    deltaHiddenOutput[i, j] = 0.0;
                    LagdeltaHiddenOutput[i, j] = 0.0;
                }
                deltaOutputBias[i] = 0.0;
                LagdeltaOutputBias[i] = 0.0;
            }
            while (MAE > expectedError && epoch < 5000)
            {
                MAE = 0.0;
                /*training for each epoch*/
                for (i = m_iNumInputNodes; i < sample.Count; i++)
                {
                    //forward
                    /* calculate output of input nodes*/
                    for (j = m_iNumInputNodes; j > 0; j--)
                    {
                        m_arInputNodes[m_iNumInputNodes - j].SetOutput(sample.ElementAt(i - j));
                    }
                    /*calculate output of hidden nodes*/
                    for (j = 0; j < m_iNumHiddenNodes; j++)
                    {
                        double net = 0.0;
                        for (int k = 0; k < m_iNumInputNodes; k++)
                        {
                            net += m_arInputNodes[k].GetOutPut() * m_arInputHiddenConn[j, k];
                        }
                        net += m_arHiddenBias[j];
                        m_arHiddenNodes[j].CalOutput(net);
                    }
                    /*calculate output of output nodes*/
                    for (j = 0; j < m_iNumOutputNodes; j++)
                    {
                        double net = 0.0;
                        for (int k = 0; k < m_iNumHiddenNodes; k++)
                        {
                            net += m_arHiddenNodes[k].GetOutPut() * m_arHiddenOutputConn[j, k];
                        }
                        net += m_arOutputBias[j];
                        m_arOutputNodes[j].CalOutput(net);
                    }
                    /*calculate square error*/
                    for (j = 0; j < m_iNumOutputNodes; j++)
                    {
                        MAE += Math.Abs(sample.ElementAt(i) - m_arOutputNodes[j].GetOutPut());
                    }
                    // backward
                    /*calculate weight-step for weights connecting from hidden nodes to output nodes*/
                    for (j = 0; j < m_iNumOutputNodes; j++)
                    {
                        for (int k = 0; k < m_iNumHiddenNodes; k++)
                        {
                            double parDerv = -m_arOutputNodes[j].GetOutPut() * (1 - m_arOutputNodes[j].GetOutPut()) * m_arHiddenNodes[k].GetOutPut() * (sample.ElementAt(i) - m_arOutputNodes[j].GetOutPut());
                            deltaHiddenOutput[j, k] = -learnRate * parDerv + momentum * LagdeltaHiddenOutput[j, k];
                            LagdeltaHiddenOutput[j, k] = deltaHiddenOutput[j, k];
                        }
                        double parDervBias = -m_arOutputNodes[j].GetOutPut() * (1 - m_arOutputNodes[j].GetOutPut()) * (sample.ElementAt(i) - m_arOutputNodes[j].GetOutPut());
                        deltaOutputBias[j] = -learnRate * parDervBias + momentum * LagdeltaOutputBias[j];
                        LagdeltaOutputBias[j] = deltaOutputBias[j];
                    }
                    /*calculate weight-step for weights connecting from input nodes to hidden nodes*/
                    for (j = 0; j < m_iNumHiddenNodes; j++)
                    {
                        double temp = 0.0;
                        for (int r = 0; r < m_iNumOutputNodes; r++)
                        {
                            temp += -(sample.ElementAt(i) - m_arOutputNodes[r].GetOutPut()) * m_arOutputNodes[r].GetOutPut() * (1 - m_arOutputNodes[r].GetOutPut()) * m_arHiddenOutputConn[r, j];
                        }
                        for (int k = 0; k < m_iNumInputNodes; k++)
                        {
                            double parDerv = m_arHiddenNodes[j].GetOutPut() * (1 - m_arHiddenNodes[j].GetOutPut()) * m_arInputNodes[k].GetOutPut() * temp;
                            deltaInputHidden[j, k] = -learnRate * parDerv + momentum * LagdeltaInputHidden[j, k];
                            LagdeltaInputHidden[j, k] = deltaInputHidden[j, k];
                        }
                        double parDervBias = m_arHiddenNodes[j].GetOutPut() * (1 - m_arHiddenNodes[j].GetOutPut()) * temp;
                        deltaHiddenBias[j] = -learnRate * parDervBias + momentum * LagdeltaHiddenBias[j];
                        LagdeltaHiddenBias[j] = deltaHiddenBias[j];
                    }
                    /*updating weight from Input to Hidden*/
                    for (j = 0; j < m_iNumHiddenNodes; j++)
                    {
                        for (int k = 0; k < m_iNumInputNodes; k++)
                        {
                            m_arInputHiddenConn[j, k] += deltaInputHidden[j, k];
                        }
                    }
                    /*updating weight from Hidden to Output*/
                    for (j = 0; j < m_iNumOutputNodes; j++)
                    {
                        for (int k = 0; k < m_iNumHiddenNodes; k++)
                        {
                            m_arHiddenOutputConn[j, k] += deltaHiddenOutput[j, k];
                        }
                    }

                } // end outer for
                MAE = MAE / (sample.Count); // caculate mean square error
                epoch++;
            }

        }


        /*
          * training the network by Resilient Backpropogation algorithm
          * sample is data used to train 
          * Author: DataMining-Research08
          */
        public void Rprop_Train(List<double> sample)
        {
            PB_Form form = new PB_Form();
            List<double> sample2 = new List<double>();
            if (form.ok == true)
            {
                /*convert input to [0.01-0.99]*/
                double max = sample.Max();
                double min = sample.Min();
                int count = sample.Count;
                for (int i = 0; i < count; i++)
                {
                    double a = sample.ElementAt(i);
                    double b = (a - min) / (max - min) * (0.99 - 0.01) + 0.01;
                    sample2.Add(b);
                }
                Rprop_run(sample2, form.learn, form.momen, form.error);
                show();
                System.Windows.MessageBox.Show("Traning finish!!!");
            }

        }
 
        /*
        * training the network by RPROP algorithm
        * sample is data used to train 
        * Author: DataMining-Research08
        */
        public void Rprop_Train(List<double> sample, double expectedError = 0.01) 
        {
            int i, j;
            int epoch = 0;
            double MAE = Double.MaxValue;
            double defaultDelta = 0.0;
            double defaultUpdate = 0.1;
            double defaultGradient = 0.0;
            double maxUpdate = 50;
            double minUpdate = 0.001;
            double updateIncrease = 1.2;
            double updateDecrease = 0.5;

            double[,] deltaInputHidden = new double[m_iNumHiddenNodes, m_iNumInputNodes];
            double[,] updateInputHidden = new double[m_iNumHiddenNodes, m_iNumInputNodes];
            double[,] gradientInputHidden = new double[m_iNumHiddenNodes, m_iNumInputNodes];

            double[,] deltaHiddenOutput = new double[m_iNumOutputNodes, m_iNumHiddenNodes];
            double[,] updateHiddenOutput = new double[m_iNumOutputNodes, m_iNumHiddenNodes];
            double[,] gradientHiddenOutput = new double[m_iNumOutputNodes, m_iNumHiddenNodes];

            double[] deltaHiddenBias = new double[m_iNumHiddenNodes];
            double[] updateHiddenBias = new double[m_iNumHiddenNodes];
            double[] gradientHiddenBias = new double[m_iNumHiddenNodes];

            double[] deltaOutputBias = new double[m_iNumOutputNodes];
            double[] updateOutputBias = new double[m_iNumOutputNodes];
            double[] gradientOutputBias = new double[m_iNumOutputNodes];

            // initialize Input Hidden connection
            for (i = 0; i < m_iNumHiddenNodes; i++)    
            {
                for (j = 0; j < m_iNumInputNodes; j++)
                {
                    deltaInputHidden[i, j] = defaultDelta;
                    updateInputHidden[i, j] = defaultUpdate;
                    gradientInputHidden[i, j] = defaultGradient;
                }
                deltaHiddenBias[i] = defaultDelta;
                updateHiddenBias[i] = defaultUpdate;
                gradientHiddenBias[i] = defaultGradient;
            }

            // initialize Hidden Output connection
            for (i = 0; i < m_iNumOutputNodes; i++)   
            {
                for (j = 0; j < m_iNumHiddenNodes; j++)
                {
                    deltaHiddenOutput[i, j] = defaultDelta;
                    updateHiddenOutput[i, j] = defaultUpdate;
                    gradientHiddenOutput[i, j] = defaultGradient;
                }
                deltaOutputBias[i] = defaultDelta;
                updateOutputBias[i] = defaultUpdate;
                gradientOutputBias[i] = defaultGradient;
            }

            while (MAE > expectedError && epoch < 5000)
            {
                MAE = 0.0;
                //training for each epoch
                for (i = m_iNumInputNodes; i < sample.Count; i++)
                {
                    //forward
                    for (j = m_iNumInputNodes; j > 0; j--)
                    {
                        m_arInputNodes[m_iNumInputNodes - j].SetOutput(sample[i - j]);
                    }
                    /*calculate output of hidden nodes*/
                    for (j = 0; j < m_iNumHiddenNodes; j++)
                    {
                        double net = 0.0;
                        for (int k = 0; k < m_iNumInputNodes; k++)
                        {
                            net += m_arInputNodes[k].GetOutPut() * m_arInputHiddenConn[j, k];
                        }
                        net += m_arHiddenBias[j];
                        m_arHiddenNodes[j].CalOutput(net);
                    }
                    /*calculate output of output nodes*/
                    for (j = 0; j < m_iNumOutputNodes; j++)
                    {
                        double net = 0.0;
                        for (int k = 0; k < m_iNumHiddenNodes; k++)
                        {
                            net += m_arHiddenNodes[k].GetOutPut() * m_arHiddenOutputConn[j, k];
                        }
                        net += m_arOutputBias[j];
                        m_arOutputNodes[j].CalOutput(net);
                    }
                    /*calculate square error*/
                    for (j = 0; j < m_iNumOutputNodes; j++)
                    {
                        MAE += Math.Abs(sample[i] - m_arOutputNodes[j].GetOutPut());
                    }
                    // backward
                    /*calculate weight-step for weights connecting from hidden nodes to output nodes*/
                    for (j = 0; j < m_iNumOutputNodes; j++)
                    {
                        for (int k = 0; k < m_iNumHiddenNodes; k++)
                        {
                            double newGradient = - m_arOutputNodes[j].GetOutPut() * (1 - m_arOutputNodes[j].GetOutPut()) * m_arHiddenNodes[k].GetOutPut() * (sample[i] - m_arOutputNodes[j].GetOutPut());
                            if (newGradient * gradientHiddenOutput[j, k] > 0)
                            {
                                updateHiddenOutput[j, k] = Math.Min(updateHiddenOutput[j, k] * updateIncrease, maxUpdate);
                                deltaHiddenOutput[j, k]  += -Math.Sign(newGradient) * updateHiddenOutput[j, k];
                                gradientHiddenOutput[j, k] = newGradient;
                            }
                            else if (newGradient * gradientHiddenOutput[j, k] < 0)
                            {
                                updateHiddenOutput[j, k] = Math.Max(updateHiddenOutput[j, k] * updateDecrease, minUpdate);
                                gradientHiddenOutput[j, k] = 0;
                            }
                            else
                            {
                                deltaHiddenOutput[j, k] += -Math.Sign(newGradient) * updateHiddenOutput[j, k];
                                gradientHiddenOutput[j, k] = newGradient;
                            }
                        }
                        double newGradientBias = -m_arOutputNodes[j].GetOutPut() * (1 - m_arOutputNodes[j].GetOutPut()) * (sample.ElementAt(i) - m_arOutputNodes[j].GetOutPut());
                        if (newGradientBias * gradientOutputBias[j] > 0)
                        {
                            updateOutputBias[j] = Math.Min(updateOutputBias[j] * updateIncrease, maxUpdate);
                            deltaOutputBias[j]  += -Math.Sign(newGradientBias) * updateOutputBias[j];
                            gradientOutputBias[j] = newGradientBias;
                        }
                        else if (newGradientBias * gradientOutputBias[j] > 0)
                        {
                            updateOutputBias[j] = Math.Max(updateOutputBias[j] * updateDecrease, minUpdate);
                            gradientOutputBias[j] = 0;
                        }
                        else
                        {
                            deltaOutputBias[j] += -Math.Sign(newGradientBias) * updateOutputBias[j];
                            gradientOutputBias[j] = newGradientBias;
                        }
                    }
                    /*calculate weight-step for weights connecting from input nodes to hidden nodes*/
                    for (j = 0; j < m_iNumHiddenNodes; j++)
                    {
                        double temp = 0.0;
                        for (int r = 0; r < m_iNumOutputNodes; r++)
                        {
                            temp += -(sample.ElementAt(i) - m_arOutputNodes[r].GetOutPut()) * m_arOutputNodes[r].GetOutPut() * (1 - m_arOutputNodes[r].GetOutPut()) * m_arHiddenOutputConn[r, j];
                        }
                        for (int k = 0; k < m_iNumInputNodes; k++)
                        {
                            double newGradient = m_arHiddenNodes[j].GetOutPut() * (1 - m_arHiddenNodes[j].GetOutPut()) * m_arInputNodes[k].GetOutPut() * temp;
                            if (newGradient * gradientInputHidden[j, k] > 0)
                            {
                                updateInputHidden[j, k] = Math.Min(updateInputHidden[j, k] * updateIncrease, maxUpdate);
                                deltaInputHidden[j, k]  += -Math.Sign(newGradient) * updateInputHidden[j, k];
                                gradientInputHidden[j, k] = newGradient;
                            }
                            else if (newGradient * gradientInputHidden[j, k] < 0)
                            {
                                updateInputHidden[j, k] = Math.Max(updateInputHidden[j, k] * updateDecrease, minUpdate);
                                gradientInputHidden[j, k] = 0;
                            }
                            else
                            {
                                deltaInputHidden[j, k] += -Math.Sign(newGradient) * updateInputHidden[j, k];
                                gradientInputHidden[j, k] = newGradient;
                            }
                        }
                        double newGradientBias = m_arHiddenNodes[j].GetOutPut() * (1 - m_arHiddenNodes[j].GetOutPut()) * temp;
                        if (newGradientBias * gradientHiddenBias[j] > 0)
                        {
                            updateHiddenBias[j] = Math.Min(updateHiddenBias[j] * updateIncrease, maxUpdate);
                            deltaHiddenBias[j]  += -Math.Sign(newGradientBias) * updateHiddenBias[j];
                            gradientHiddenBias[j] = newGradientBias;
                        }
                        else if (newGradientBias * gradientHiddenBias[j] > 0)
                        {
                            updateHiddenBias[j] = Math.Max(updateHiddenBias[j] * updateDecrease, minUpdate);
                            gradientHiddenBias[j] = 0;
                        }
                        else
                        {
                            deltaHiddenBias[j] += -Math.Sign(newGradientBias) * updateHiddenBias[j];
                            gradientHiddenBias[j] = newGradientBias;
                        }
                    }

                } // end outer for

                    /*updating weight from Input to Hidden*/
                    for (j = 0; j < m_iNumHiddenNodes; j++)
                    {
                        for (int k = 0; k < m_iNumInputNodes; k++)
                        {
                            m_arInputHiddenConn[j, k] += deltaInputHidden[j, k];
                        }
                    }
                    /*updating weight from Hidden to Output*/
                    for (j = 0; j < m_iNumOutputNodes; j++)
                    {
                        for (int k = 0; k < m_iNumHiddenNodes; k++)
                        {
                            m_arHiddenOutputConn[j, k] += deltaHiddenOutput[j, k];
                        }
                    }
                MAE = MAE / (sample.Count); // caculate mean square error
                epoch++;
            }
        }

        /**
         * Note: PD stands for "Partial Derivativess"
         */
        private int sign(double currentPD, double pastPD)
        {
            double equal = currentPD * pastPD;
            if (equal > 0)
            {
                return 1;
            }
            else if (equal < 0)
            {
                return -1;
            }
            else
            {
                return 0;
            }
        }

        public void show(){
            Console.WriteLine("Bias of Hidden layer: ");
            for (int i = 0; i < m_iNumHiddenNodes; i++)
            {
                Console.WriteLine("Hidden node #" + i + " : " + m_arHiddenBias[i]); 
            }
            Console.WriteLine("\nWeight of Input - Hidden layer: ");
            for (int j = 0; j < m_iNumInputNodes; j++)
            {
                for (int i = 0; i < m_iNumHiddenNodes; i++)
                {
                    Console.WriteLine("[" + j + "," + i + "] : " + m_arInputHiddenConn[j,i]);
                }
            }
            Console.WriteLine("Bias of Output layer: ");
            for (int i = 0; i < m_iNumOutputNodes; i++)
            {
                Console.WriteLine("Output node #" + i + " : " + m_arOutputBias[i]);
            }
            Console.WriteLine("\nWeight of output - Hidden layer: ");
            for (int j = 0; j < m_iNumOutputNodes; j++)
            {
                for (int i = 0; i < m_iNumHiddenNodes; i++)
                {
                    Console.WriteLine("[" + j + "," + i + "] : " + m_arHiddenOutputConn[j, i]);
                }
            }

        }

    }
}
